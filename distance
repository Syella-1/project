import aiohttp
import asyncio
import aiofiles
from bs4 import BeautifulSoup
import re

links = [
"https://en.wikipedia.org/wiki/2007%E2%80%9308_Scottish_League_Cup",
"https://en.wikipedia.org/wiki/Philosophy"
]
async def fetch_html(session, url):
async with session.get(url) as response:
return await response.text()

async def parse_links(html):
soup = BeautifulSoup(html, 'html.parser')
found_links = [link.get('href') for link in soup.find_all('a', href=True)]
return found_links

async def write_links_to_file(links):
async with aiofiles.open('found_links.txt', 'a') as file:
for link in links:
await file.write(link + '\n')

async def find_distance(session, url1, url2):
 html1 = await fetch_html(session, url1)
html2 = await fetch_html(session, url2)
    
links1 = await parse_links(html1)
links2 = await parse_links(html2)
    
distance = len(set(links1).symmetric_difference(set(links2)))
return distance

async def main():
async with aiohttp.ClientSession() as session:
tasks = [find_distance(session, links[0], links[1])]
distances = await asyncio.gather(*tasks)
print(f"Distance between {links[0]} and {links[1]} is: {distances[0]}")

if __name__ == 'main':
asyncio.run(main())
